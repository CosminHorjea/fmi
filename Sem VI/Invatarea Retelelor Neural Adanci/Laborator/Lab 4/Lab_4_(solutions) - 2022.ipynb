{"cells":[{"cell_type":"markdown","metadata":{"id":"NjZTLbz4Vx4c"},"source":["<font size=25>Laboratory 4 summary</font>\n","\n","In this lab you will gain debugging experience by solving the most typical deep learning bugs. \n","\n","There are 8 exercises, each one with a corresponding cell. Run the cell, inspect the error and fix the code. The bugs can be fixed by editing one or two lines of code."]},{"cell_type":"markdown","metadata":{"id":"HUoo-4E12opk"},"source":["# **Bugs everywhere**"]},{"cell_type":"code","source":["from __future__ import print_function, division\n","import os\n","import torch\n","import random\n","from typing import Iterator, List, Callable, Tuple\n","from functools import partial\n","import warnings\n","from math import *\n","import zipfile\n","from tqdm import tqdm\n","from PIL import Image\n","\n","# Sklearn\n","from sklearn.datasets import load_digits\n","# Numpy\n","import numpy as np\n","# Pandas\n","import pandas as pd\n","\n","# PyTorch packages\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","from torch.utils.data import RandomSampler, Sampler\n","from torchvision import transforms, utils, datasets\n","from torchvision.transforms import ToTensor, ToPILImage\n","import torch.nn as nn\n","\n","# matplotlib\n","from matplotlib import rc, cm\n","rc('animation', html='jshtml')\n","import matplotlib.pyplot as plt\n","from mpl_toolkits import mplot3d\n","import matplotlib.animation as animation\n","%matplotlib notebook\n","#warnings.filterwarnings(\"ignore\")\n","plt.ion()   # interactive mode"],"metadata":{"id":"8vvjpuXSFmFD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BsINHO_NwDv5"},"source":["## Exercise 1: Getting started\n"]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size: int, \n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.hidden_layer = nn.Linear(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, 2)\n","        self.activation_fn = activation_fn\n","\n","    def forward(self, x):\n","        h = self.hidden_layer(x)\n","        h = self.activation_fn(h)\n","        out = self.output_layer(h)\n","\n","        return out\n","\n","model = MLP(input_size=100, hidden_size=256, activation_fn=nn.ReLU())\n","\n","# issue: wrong input shape\n","#x = torch.rand(32, 200)\n","\n","# solution\n","x = torch.rand(32, 100)\n","\n","y = model(x)\n","assert y.shape[0] == 32 and y.shape[1] == 2, \"Wrong output shape\""],"metadata":{"id":"k1BvB8TwEPzx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 2: Getting in shape"],"metadata":{"id":"uHW1o4myBc4m"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size: int, \n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.hidden_layer = nn.Linear(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, 2)\n","        self.activation_fn = activation_fn\n","\n","    def forward(self, x):\n","        h = self.hidden_layer(x)\n","        h = self.activation_fn(h)\n","        out = self.output_layer(h)\n","\n","        return out\n","\n","model = MLP(input_size=784, hidden_size=256, activation_fn=nn.ReLU())\n","mnist_trainset = datasets.MNIST(\n","    root='./data', \n","    train=True, \n","    download=True, \n","    transform=transforms.ToTensor())\n","x, l = mnist_trainset[10]\n","\n","# issue: shape of x is 1x3x32x32, but the network takes a tensor of shape 784\n","# solution: resize x before feeding it to the network\n","# when -1 is passed as an argument, the actual dimension is inferred from the\n","# remaining dimensions\n","# 1x3x32x32 -> 1x(784)\n","x = x.view(1, -1) \n","y = model(x)\n","assert y.shape[0] == 1 and y.shape[1] == 2, \"Wrong output shape\""],"metadata":{"id":"3GCJ9iNHNFIe","colab":{"base_uri":"https://localhost:8080/","height":422,"referenced_widgets":["883fad93f31f470daa43a935f7d783cf","e834c410aa61426f88a777a07b0903a3","1799fade7b6946a6965dc9e429825646","e664bde2f3ce4d6580c61d53e20b7f34","ef5f12e81edd42e0b05a12cb650ae80b","699409330a4446b8a3d52efd0ceb8e85","9087eea5ef784425a4ea365650395f6a","13d951b103b140878839e637f6321a4a","297f574520e84587a88996670bf15201","86ff251cfdf94fcf9f2a3d2284dbe783","a6f01ae95f2d49c7b60aedd2a480fd59","041f4cf7c3714fa98276e121d027f119","5c393deb781c420c886b01fbc64dc472","21adfff2ae3b492a99b8c8586bb207d0","6c2ddff656254c07bed765fb430334d9","b81fe0aa48594df58ee1ed7031f1b940","e2b3f17d4e15483bb85836ac300c4d4c","92b8229b23fc487fbbff57449e384bb6","7b1d0406bc9b43debf746b1ab9b52cdf","5922382683eb46fcbd53962b5fd174b6","48074a8a1ff643c1bbfe1f3cb5609961","fc5b191b96a042e4859060623277ba61","c3aba9c795294ce1b132b275a0402d28","4ed2e99e396a4bc8829c1e26858276d0","785cc177c75b441c95b4a665c9c0c434","224ae4d91314455b8dc7b6c95045e26a","a2c0b293722a4135bb4a7e66307332c7","e1e805291518436f9eba9e39fcac4735","3de1243df1cf41b5abe6e56297aece73","4b97d10fbdd244a7be379e669eb4505d","68503b9ac30e4c02a6ba29d4ca42bb9b","c124f53285a341009cde32ae79313eae","eb522ac759b244428f8e6c2ab0e81dfe","0fb126b1df8a4d34bd1f643bc90e5340","9681a143869a45beb99a550b846a5c9b","3ee6599a88df42f59d6b76d39c60ecd6","a22eafba642c4d66b62955edc6b28156","61c1dcb1fe7d47b18afa8fdaa61143dc","162fb8717496497e87ee1fd48f775fe9","1245a0d2a3454d969621dcc1faa0edc7","c29b36cbdae749a28871d3689e4bbcd9","1b134493975546a9a56f4164c01c4ac5","2b247722da0c4cc5957cfa60dc998f5e","bd2c6a2480134e6c816be72c731a2bbf"]},"executionInfo":{"status":"ok","timestamp":1646397203504,"user_tz":-120,"elapsed":1244,"user":{"displayName":"Florin Brad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06472899283008656976"}},"outputId":"26c96b15-7ff6-4344-adf6-b921969ff137"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"883fad93f31f470daa43a935f7d783cf","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"041f4cf7c3714fa98276e121d027f119","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3aba9c795294ce1b132b275a0402d28","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fb126b1df8a4d34bd1f643bc90e5340","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]}]},{"cell_type":"markdown","source":["## Exercise 3: It's the little things"],"metadata":{"id":"3beV3q_MBf4u"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size: int, \n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.hidden_layer = nn.Linear(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, 2)\n","        self.activation_fn = activation_fn\n","\n","    def forward(self, x):\n","        h = self.hidden_layer(x)\n","        \n","        # issue: activation_fn is accidentally applied over x\n","        # instead of h => shape mismatch\n","        # h = self.activation_fn(x)\n","\n","        # solution: \n","        h = self.activation_fn(h)\n","        \n","        out = self.output_layer(h)\n","\n","        return out\n","\n","# issue: activation_fn is accidentally passed as a function pointer,\n","# instead of object\n","# model = MLP(input_size=784, hidden_size=256, activation_fn=nn.ReLU)\n","\n","# solution:\n","model = MLP(input_size=784, hidden_size=256, activation_fn=nn.ReLU())\n","\n","x = torch.rand(32, 784)\n","y = model(x)\n","assert y.shape[0] == 32 and y.shape[1] == 2, \"Wrong output shape\""],"metadata":{"id":"ijj1R6SXP-fc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 4: No one left behind"],"metadata":{"id":"QAJtebM_Bjck"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size: int, \n","                 batch_size: int,\n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.hidden_layer = nn.Linear(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, 10)\n","        self.batch_size = batch_size\n","        self.activation_fn = activation_fn\n","\n","    def forward(self, x):\n","        # issue: for batch_size=32, we always expected tensors of size \n","        # 32 x 1 x 28 x 28. However, the last batch in the dataset was 16,\n","        # so the view function below reshaped the 16 x 1 x 28 x 28 tensor to\n","        # 32 x (1 x 14 x 14) = 32 x 784. This new dimension (784) turned out\n","        # to be incompatible with the first layer of the network\n","        # -\n","        # input x has shape: batch_size x 1 x 28 x 28 \n","        # we resize it to:   batch_size x 784\n","        # x = x.view(self.batch_size, -1)\n","\n","        # solution 2:\n","        # We extract the actual batch size first and then resize the tensor\n","        # accordingly.\n","        current_batch_size = x.shape[0]\n","        x = x.view(current_batch_size, -1)\n","\n","        # solution 3:\n","        # We resize the tensor based on the 1st input layer dimension\n","        x = x.view(-1, 784)\n","\n","        h = self.hidden_layer(x)\n","        h = self.activation_fn(h)\n","        out = self.output_layer(h)\n","\n","        return out\n","\n","# instantiate model\n","BATCH_SIZE=32\n","model = MLP(\n","    input_size=784, \n","    hidden_size=256, \n","    activation_fn=nn.ReLU(), \n","    batch_size=BATCH_SIZE\n",")\n","\n","# instantiate MNIST dataset\n","val_dataset = datasets.MNIST(\n","    root='./data', \n","    train=False, \n","    download=True, \n","    transform=transforms.ToTensor())\n","print(\"validation dataset size = \", len(val_dataset))\n","\n","# issue: dataset has 10000 examples, so the last batch has only 16 elements\n","# instead of 32. The forward method in the MLP class has a bug.\n","# It accidentally reshapes the last batch Tensor from 16 x 1 x 28 x 28\n","# to 32 x (1 x 14 x 14) = 32 x 196. Therefore, the new tensor shape is\n","# incompatible with the first layer of the model.\n","# val_dataloader = DataLoader(\n","#     val_dataset,\n","#     batch_size=BATCH_SIZE,\n","#     shuffle=True\n","# )\n","\n","# solution 1: set the drop_last argument in the DataLoader to True. This\n","# drops the last batch (which may have a different shape) so that all\n","# the batches have the same number of examples\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    drop_last=False\n",")\n","\n","loss_crt = nn.CrossEntropyLoss()\n","epoch_loss = 0.0\n","for batch_images, batch_labels in val_dataloader:\n","    # batch_size x 2\n","    out = model(batch_images)\n","    loss = loss_crt(out, batch_labels)\n","    epoch_loss += loss.item()\n","\n","epoch_loss /= len(val_dataloader)\n","print(\"Validation loss = \", epoch_loss)"],"metadata":{"id":"cbXjL4t37_JZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 5: Left to their own devices\n"],"metadata":{"id":"BvVmqB1tHSF4"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size: int, \n","                 batch_size: int,\n","                 device: torch.device,\n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.hidden_layer = nn.Linear(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, 10)\n","        self.activation_fn = activation_fn\n","        self.device = device\n","        self.batch_size = batch_size\n","\n","    def forward(self, x):\n","        # issue: Tensor.to() is not an in-place operation, so tensor x\n","        # remains on CPU\n","        # -\n","        # move input data to GPU (if available)\n","        # x.to(self.device)\n","\n","        # solution\n","        x = x.to(self.device)\n","\n","        # reshape tensor\n","        # batch_size x 784\n","        x = x.view(self.batch_size, -1)\n","\n","        h = self.hidden_layer(x)\n","        h = self.activation_fn(h)\n","        out = self.output_layer(h)\n","\n","        return out\n","\n","BATCH_SIZE=32\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(\"device = \", device)\n","\n","# instantiate model\n","model = MLP(\n","    input_size=784, hidden_size=256, activation_fn=nn.ReLU(), batch_size=32,\n","    device=device\n",")\n","\n","# move model to GPU (Module.to() is an in-place operation)\n","model.to(device)\n","\n","# instantiate MNIST dataset\n","train_dataset = datasets.MNIST(\n","    root='./data', \n","    train=True, \n","    download=True, \n","    transform=transforms.ToTensor())\n","print(\"train dataset size = \", len(train_dataset))\n","\n","# instantiate dataloader\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n",")\n","\n","loss_crt = nn.CrossEntropyLoss()\n","epoch_loss = 0.0\n","for batch_images, batch_labels in train_dataloader:\n","    # issue: Tensor.to() is not an in-place operation (though Model.to() is)\n","    # therefore batch_labels remains on CPU\n","    # -\n","    # move labels to GPU (if available)\n","    # batch_labels.to(device)\n","\n","    # solution:\n","    #batch_labels=batch_labels.to(device)\n","    \n","    # batch_size x 2\n","    # feedforward\n","    out = model(batch_images)\n","    \n","    # compute loss \n","    loss = loss_crt(out, batch_labels)\n","    epoch_loss += loss.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":855,"referenced_widgets":["82ee47d85da04df6bbec5bc2dbbc0f83","eb23187ee7f84a8caf9de227f3c2a5c7","7791e791e71a4624abc0ee5f3b993837","37e20b1658cf471eb5e9e3eb60d8f714","fe9857e31d144161ab3dfa0da694cfb2","70242058f5f445958cfc2f5cc97f9fc2","539d613253f046d9ba3d5a6cca4e7336","78c4fcd456d043cabaf5cbbe2759162d","c250ff8c5f6741f7b8aeee35bb875ed0","0d6cff1d27b24792807bf5ddd1b2b98a","5b5b1b3d8df54e93b536623d8ba108b2","5625556804e1402ea35bad12a50602a7","b79f4a06afae43bfb8d52b8164550dcf","f693688ab84e4409864468718e1f65ea","1fcad33212074d7190cee61b0acf06a1","2932938c95c14112bac48bd31b2cb20a","072664088ed34e049ccc45b1543235a3","46f5a980615c4cd388def319f7f3a721","8d2ccc5e585c42db99e35f967fb3ea10","8b107775747e4ebfb7b2e7f17817631e","b805a7f4aae64af4acea9567d2508e8a","dc81171d82814f8cb5447878eb0ff5e2","8883d141ffe74da8b8c13c1e58047513","355b3351b29d4961a4e5cdaacf262734","1e483e2e124040fc8a035ea3179b189f","a783b52295e2472e85da514318004f59","8d71cb6a6c334edaaed30e4314db24f1","a394c7b2e9d54998b47008230cca4e19","00721e39470c4c87843c62304fcf5eaa","fda2cb5f22654485ae6825284bb502da","3e4bb6fe52b94972a4e764cd3cba2861","bb79ebc20ff3436ab81285dd53bf0f7d","c2394553a493485198b4b25e4dbdaf41","96e2e4cbff4f4b8ba62f8353f2a9c6f2","b23c1c008bbf41f59e0e5605132fe900","9a14590276dc4c5ca20dbceaacccbd72","e00bb6d2dc014523a1df7681cd07dbc1","a1918aae919e4493bf4880368a56e5ff","40b9c5938cf84c728b746e90602fd7e8","8671ca14c40e43fe85e76733243cf809","79048debe5f040978bdd7d3a95a36478","ac3308818c5842d4887aa7e0db7cac7f","f7be7a221d0a463abb1498227798797f","33d595b780c34d358cf151b4c33a46f6"]},"id":"bymjthPlMBY3","executionInfo":{"status":"error","timestamp":1646774491904,"user_tz":-120,"elapsed":17631,"user":{"displayName":"Florin Brad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06472899283008656976"}},"outputId":"eea0ab2b-404a-4ab5-8c7f-8fff412021b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device =  cuda\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82ee47d85da04df6bbec5bc2dbbc0f83","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5625556804e1402ea35bad12a50602a7","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8883d141ffe74da8b8c13c1e58047513","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96e2e4cbff4f4b8ba62f8353f2a9c6f2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","train dataset size =  60000\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c6698a8d7da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_crt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument target in method wrapper_nll_loss_forward)"]}]},{"cell_type":"markdown","source":["## Exercise 6: Not exactly my type"],"metadata":{"id":"6xEcE46Y9q74"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size: int, \n","                 device: torch.device,\n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.hidden_layer = nn.Linear(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, 10)\n","        self.activation_fn = activation_fn\n","        self.device = device\n","\n","    def forward(self, x):\n","        # batch_size x 64\n","        x = x.to(self.device)\n","\n","        h = self.hidden_layer(x)\n","        h = self.activation_fn(h)\n","        out = self.output_layer(h)\n","\n","        return out\n","\n","BATCH_SIZE=32\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(\"device = \", device)\n","\n","# instantiate model\n","model = MLP(\n","    input_size=64, hidden_size=256, activation_fn=nn.ReLU(), device=device\n",")\n","\n","# move model to GPU (Module.to() is an in-place operation)\n","model.to(device)\n","\n","# load the 1797 images from the Digits dataset:\n","# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html\n","# Images are grayscale digits from 0 to 9, stored as arrays of size 64 (8x8). \n","# Both images and labels are stored are NumPy arrays, so we need to convert \n","# them to Tensors.\n","x = load_digits()\n","\n","# issue: NumPy arrays are 64bit floating point type, so torch.tensor() converts \n","# them to Tensors of type Double (torch.float64) by default. However,\n","# the default type of Tensors is torch.float32, so when we instantiated the\n","# model, its parameters have type torch.float32 as well. This leads to a \n","# type mismatch when feeding a torch.float64 input to the first layer.\n","# -\n","# 1797 x 64, 1797\n","#images, labels = torch.tensor(x.data), torch.tensor(x.target)\n","\n","# solution 1: specify dtype argument in the torch.tensor() constructor\n","images, labels = torch.tensor(x.data, dtype=torch.float32), torch.tensor(x.target)\n","\n","# solution 2: use torch.to(dtype=torch.float32) to convert to Float type\n","images, labels = torch.tensor(x.data), torch.tensor(x.target)\n","images = images.to(dtype=torch.float32)\n","\n","# solution 3: call .float() on tensor to convert it to Float type\n","images, labels = torch.tensor(x.data), torch.tensor(x.target)\n","#images = images.float()\n","\n","# we create a TensorDataset, which is a type of Dataset that wraps Tensors.\n","# https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset\n","# Examples are indexed over the first dimension, so the first dimension of \n","# the Tensors must be the same (1797 in our case)\n","train_dataset = TensorDataset(images, labels)\n","\n","# instantiate dataloader\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n",")\n","\n","loss_crt = nn.CrossEntropyLoss()\n","epoch_loss = 0.0\n","for batch_images, batch_labels in train_dataloader:\n","    batch_labels=batch_labels.to(device)\n","    \n","    # batch_size x 2\n","    # feedforward\n","    out = model(batch_images)\n","    \n","    # compute loss \n","    loss = loss_crt(out, batch_labels)\n","    epoch_loss += loss.item()"],"metadata":{"id":"WDdeFJtSW0ea","colab":{"base_uri":"https://localhost:8080/","height":883},"executionInfo":{"status":"error","timestamp":1646747702893,"user_tz":-120,"elapsed":428,"user":{"displayName":"Florin Brad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06472899283008656976"}},"outputId":"1660b6f1-b09d-470b-9815-06083c06b187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device =  cuda\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-0029f6242748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# batch_size x 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# feedforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-0029f6242748>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"]}]},{"cell_type":"code","source":["x = torch.tensor([3,4])"],"metadata":{"id":"VXl4MYtJtSy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x[-5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"lEkOI3E1y2Gf","executionInfo":{"status":"error","timestamp":1646749206943,"user_tz":-120,"elapsed":415,"user":{"displayName":"Florin Brad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06472899283008656976"}},"outputId":"f51376a1-2203-4d0a-8d74-5c6814bf9ea1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-3f8aa68a9513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: index -5 is out of bounds for dimension 0 with size 2"]}]},{"cell_type":"code","source":["x = m(y)"],"metadata":{"id":"2sUUhmxy1B71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 7: Out of bounds\n","The [Wheat Seeds](https://archive.ics.uci.edu/ml/datasets/seeds) dataset ([Kaggle link](https://www.kaggle.com/jmcaro/wheat-seedsuci)) is a classification task with 3 classes, which contains 209 examples. Each example contains 7 geometrical properties of wheat seeds belonging to 3 varieties of wheat. \n","\n","**Hint 1:** When training on GPUs, CUDA errors may be less helpful. Usually, errors such as \"`RuntimeError: CUDA error: device-side assert triggered`\" indicate a problem with an index, which may be too large. To get a more accurate error message, move the model and dataset to CPU, check the error again and try to fix it.\n","\n","**Hint 2:** After fixing the code responsible for a CUDA error, you may still encounter the error when running on GPU. Try restarting the Colab Notebook (`Runtime` -> `Restart runtime`) and run the cells again.\n"],"metadata":{"id":"1WRHhMa4nX8R"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size: int, \n","                 device: torch.device,\n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.hidden_layer = nn.Linear(input_size, hidden_size)\n","        self.output_layer = nn.Linear(hidden_size, 3)\n","        self.activation_fn = activation_fn\n","        self.device = device\n","\n","    def forward(self, x):\n","        # batch_size x 7\n","        x = x.to(self.device)\n","\n","        h = self.hidden_layer(x)\n","        h = self.activation_fn(h)\n","        out = self.output_layer(h)\n","\n","        return out\n","\n","BATCH_SIZE=32\n","\n","# if you encounter a vague CUDA error message, move the operations to CPU then\n","# run the code again. The error message is usually more helpful.\n","#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","device = torch.device('cpu')\n","print(\"device = \", device)\n","\n","# instantiate model\n","model = MLP(\n","    input_size=7, hidden_size=128, activation_fn=nn.ReLU(), device=device\n",")\n","\n","# move model to GPU (Module.to() is an in-place operation)\n","model.to(device)\n","\n","# download Wheat Seeds dataset\n","!wget --no-check-certificate \\\n","https://raw.githubusercontent.com/jbrownlee/Datasets/master/wheat-seeds.csv \\\n","-O /tmp/wheat.csv\n","\n","# read Wheat Seeds dataset from csv\n","# Dataset has 209 examples. Each example has 7 attributes (features).\n","# It's a classification task with 3 classes (1, 2 and 3)\n","data = pd.read_csv(\"/tmp/wheat.csv\")\n","\n","# issue: the labels read from the CSV are 1, 2 and 3. However, the scores that\n","# the model outputs in the `out` tensor are indexed from 0 to 2, leading to\n","# an index error when trying to access out[:, 3]\n","#x = torch.tensor(data.values, dtype=torch.float32)\n","#data, labels = x[:,:-1], x[:,-1].long()\n","\n","# solution: subtract 1 from the `labels` tensor\n","x = torch.tensor(data.values, dtype=torch.float32)\n","data, labels = x[:,:-1], x[:,-1].long()-1\n","\n","# we create a TensorDataset, which is a type of Dataset that wraps Tensors.\n","# https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset\n","# Examples are indexed over the first dimension, so the first dimension of \n","# the Tensors must be the same (209 in our case)\n","validation_dataset = TensorDataset(data, labels)\n","\n","# instantiate dataloader\n","validation_dataloader = DataLoader(\n","    validation_dataset,\n","    batch_size=BATCH_SIZE\n",")\n","\n","loss_crt = nn.CrossEntropyLoss()\n","epoch_loss = 0.0\n","for batch_images, batch_labels in validation_dataloader:\n","    batch_labels=batch_labels.to(device)\n","    \n","    # feedforward\n","    # batch_size x 3\n","    out = model(batch_images)\n","    \n","    # compute loss \n","    loss = loss_crt(out, batch_labels)\n","    epoch_loss += loss.item()\n","\n","epoch_loss /= len(validation_dataloader)\n","print(\"Validation loss = \", epoch_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":623},"id":"xZP5yCbeo5Pd","executionInfo":{"status":"error","timestamp":1646749072291,"user_tz":-120,"elapsed":1650,"user":{"displayName":"Florin Brad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06472899283008656976"}},"outputId":"8128f677-4124-4cce-8783-da527013af84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device =  cpu\n","--2022-03-08 14:17:50--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/wheat-seeds.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9301 (9.1K) [text/plain]\n","Saving to: ‘/tmp/wheat.csv’\n","\n","/tmp/wheat.csv      100%[===================>]   9.08K  --.-KB/s    in 0s      \n","\n","2022-03-08 14:17:51 (33.8 MB/s) - ‘/tmp/wheat.csv’ saved [9301/9301]\n","\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-98b3636302cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_crt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Target 3 is out of bounds."]}]},{"cell_type":"markdown","source":["## Exercise 8: I have no memory of that\n","\n","**Hint 1:** The error will appear after ~2 epochs\n","\n","**Hint 2:** You do NOT need to modify the model's size to fix the memory bug\n","\n","**Hint 3:** After getting the error message, you have to restart the machine:\n","  - restart Colab: `Runtime` -> `Restart runtime`\n","  - run the cell that imports packages \n","  - run the cell below"],"metadata":{"id":"4v5D0k3MHsW0"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, \n","                 input_size: int, \n","                 hidden_size_1: int, \n","                 hidden_size_2: int, \n","                 hidden_size_3: int, \n","                 hidden_size_4: int, \n","                 device: torch.device,\n","                 activation_fn: Callable):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size_1 = hidden_size_1\n","        self.hidden_size_2 = hidden_size_2\n","        self.hidden_layer_1 = nn.Linear(input_size, hidden_size_1)\n","        self.hidden_layer_2 = nn.Linear(hidden_size_1, hidden_size_2)\n","        self.hidden_layer_3 = nn.Linear(hidden_size_2, hidden_size_3)\n","        self.hidden_layer_4 = nn.Linear(hidden_size_3, hidden_size_4)\n","        self.output_layer = nn.Linear(hidden_size_4, 10)\n","        self.activation_fn = activation_fn\n","        self.device = device\n","\n","    def forward(self, x):\n","        # move input data to GPU (if available)\n","        x = x.to(self.device)\n","\n","        # reshape tensor\n","        # batch_size x 784\n","        x = x.view(-1, self.input_size)\n","\n","        h1 = self.activation_fn(self.hidden_layer_1(x))\n","        h2 = self.activation_fn(self.hidden_layer_2(h1))\n","        h3 = self.activation_fn(self.hidden_layer_3(h2))\n","        h4 = self.activation_fn(self.hidden_layer_4(h3))\n","        out = self.output_layer(h4)\n","\n","        return out\n","\n","BATCH_SIZE=32\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(\"device = \", device)\n","\n","# instantiate model\n","model = MLP(\n","    input_size=784, \n","    hidden_size_1=4096,\n","    hidden_size_2=4096,\n","    hidden_size_3=4096,\n","    hidden_size_4=4096,\n","    activation_fn=nn.ReLU(), \n","    device=device\n",")\n","\n","# move model to GPU (Module.to() is an in-place operation)\n","model.to(device)\n","\n","# instantiate MNIST dataset\n","train_dataset = datasets.MNIST(\n","    root='./data', \n","    train=True, \n","    download=True, \n","    transform=transforms.ToTensor())\n","print(\"train dataset size = \", len(train_dataset))\n","\n","# instantiate dataloader\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n",")\n","\n","loss_crt = nn.CrossEntropyLoss()\n","epoch_loss = 0.0\n","num_batches = len(train_dataloader)\n","for epoch in range(20):\n","    for idx, (batch_images, batch_labels) in enumerate(train_dataloader):\n","        if idx % 50 == 0:\n","            print(\"epoch %d, batch %d/%d\" % (epoch, idx, num_batches))\n","\n","        # move labels to GPU (if available)\n","        batch_labels=batch_labels.to(device)\n","        \n","        # batch_size x 2\n","        # feedforward\n","        out = model(batch_images)\n","        \n","        # compute loss \n","        loss = loss_crt(out, batch_labels)\n","\n","        # issue:\n","        # loss is a Tensor, which contains the whole computational graph\n","        # of the model. When adding it to the epoch_loss counter, the \n","        # computational graph of each training loop is accumulated in the\n","        # epoch_loss variable, instead of being discarded. Thus, the memory\n","        # usage continues to increase until the out of memory error appears.\n","        # you can also see this issue discussed here:\n","        # https://pytorch.org/docs/stable/notes/faq.html#my-model-reports-cuda-runtime-error-2-out-of-memory\n","        # -\n","        # epoch_loss += loss\n","\n","        \n","\n","        # solution:\n","        # extract the scalar from the loss Tensor with .item()\n","        # since the loss variable is not further used, the memory required \n","        # for the computational graph is freed after every iteration\n","        epoch_loss += loss.item()\n","\n","    epoch_loss /= num_batches\n","    print(\"epoch loss = \", epoch_loss)"],"metadata":{"id":"mAahmqrJae1h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"o_XMAAIA9r0u"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Lab_4_(solutions) - 2022.ipynb","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyP/nlLXC6hreGZA3SFx0KKj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"883fad93f31f470daa43a935f7d783cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e834c410aa61426f88a777a07b0903a3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1799fade7b6946a6965dc9e429825646","IPY_MODEL_e664bde2f3ce4d6580c61d53e20b7f34","IPY_MODEL_ef5f12e81edd42e0b05a12cb650ae80b"]}},"e834c410aa61426f88a777a07b0903a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1799fade7b6946a6965dc9e429825646":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_699409330a4446b8a3d52efd0ceb8e85","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9087eea5ef784425a4ea365650395f6a"}},"e664bde2f3ce4d6580c61d53e20b7f34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_13d951b103b140878839e637f6321a4a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_297f574520e84587a88996670bf15201"}},"ef5f12e81edd42e0b05a12cb650ae80b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_86ff251cfdf94fcf9f2a3d2284dbe783","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [00:00&lt;00:00, 52757114.66it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6f01ae95f2d49c7b60aedd2a480fd59"}},"699409330a4446b8a3d52efd0ceb8e85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9087eea5ef784425a4ea365650395f6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13d951b103b140878839e637f6321a4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"297f574520e84587a88996670bf15201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86ff251cfdf94fcf9f2a3d2284dbe783":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a6f01ae95f2d49c7b60aedd2a480fd59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"041f4cf7c3714fa98276e121d027f119":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5c393deb781c420c886b01fbc64dc472","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_21adfff2ae3b492a99b8c8586bb207d0","IPY_MODEL_6c2ddff656254c07bed765fb430334d9","IPY_MODEL_b81fe0aa48594df58ee1ed7031f1b940"]}},"5c393deb781c420c886b01fbc64dc472":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21adfff2ae3b492a99b8c8586bb207d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e2b3f17d4e15483bb85836ac300c4d4c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_92b8229b23fc487fbbff57449e384bb6"}},"6c2ddff656254c07bed765fb430334d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7b1d0406bc9b43debf746b1ab9b52cdf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5922382683eb46fcbd53962b5fd174b6"}},"b81fe0aa48594df58ee1ed7031f1b940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_48074a8a1ff643c1bbfe1f3cb5609961","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:00&lt;00:00, 756362.85it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc5b191b96a042e4859060623277ba61"}},"e2b3f17d4e15483bb85836ac300c4d4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"92b8229b23fc487fbbff57449e384bb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b1d0406bc9b43debf746b1ab9b52cdf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5922382683eb46fcbd53962b5fd174b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"48074a8a1ff643c1bbfe1f3cb5609961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fc5b191b96a042e4859060623277ba61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3aba9c795294ce1b132b275a0402d28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4ed2e99e396a4bc8829c1e26858276d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_785cc177c75b441c95b4a665c9c0c434","IPY_MODEL_224ae4d91314455b8dc7b6c95045e26a","IPY_MODEL_a2c0b293722a4135bb4a7e66307332c7"]}},"4ed2e99e396a4bc8829c1e26858276d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"785cc177c75b441c95b4a665c9c0c434":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e1e805291518436f9eba9e39fcac4735","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3de1243df1cf41b5abe6e56297aece73"}},"224ae4d91314455b8dc7b6c95045e26a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4b97d10fbdd244a7be379e669eb4505d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68503b9ac30e4c02a6ba29d4ca42bb9b"}},"a2c0b293722a4135bb4a7e66307332c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c124f53285a341009cde32ae79313eae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:00&lt;00:00, 17768079.75it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb522ac759b244428f8e6c2ab0e81dfe"}},"e1e805291518436f9eba9e39fcac4735":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3de1243df1cf41b5abe6e56297aece73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b97d10fbdd244a7be379e669eb4505d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"68503b9ac30e4c02a6ba29d4ca42bb9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c124f53285a341009cde32ae79313eae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eb522ac759b244428f8e6c2ab0e81dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fb126b1df8a4d34bd1f643bc90e5340":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9681a143869a45beb99a550b846a5c9b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3ee6599a88df42f59d6b76d39c60ecd6","IPY_MODEL_a22eafba642c4d66b62955edc6b28156","IPY_MODEL_61c1dcb1fe7d47b18afa8fdaa61143dc"]}},"9681a143869a45beb99a550b846a5c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3ee6599a88df42f59d6b76d39c60ecd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_162fb8717496497e87ee1fd48f775fe9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1245a0d2a3454d969621dcc1faa0edc7"}},"a22eafba642c4d66b62955edc6b28156":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c29b36cbdae749a28871d3689e4bbcd9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b134493975546a9a56f4164c01c4ac5"}},"61c1dcb1fe7d47b18afa8fdaa61143dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b247722da0c4cc5957cfa60dc998f5e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:00&lt;00:00, 133153.33it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd2c6a2480134e6c816be72c731a2bbf"}},"162fb8717496497e87ee1fd48f775fe9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1245a0d2a3454d969621dcc1faa0edc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c29b36cbdae749a28871d3689e4bbcd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1b134493975546a9a56f4164c01c4ac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b247722da0c4cc5957cfa60dc998f5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd2c6a2480134e6c816be72c731a2bbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"82ee47d85da04df6bbec5bc2dbbc0f83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eb23187ee7f84a8caf9de227f3c2a5c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7791e791e71a4624abc0ee5f3b993837","IPY_MODEL_37e20b1658cf471eb5e9e3eb60d8f714","IPY_MODEL_fe9857e31d144161ab3dfa0da694cfb2"]}},"eb23187ee7f84a8caf9de227f3c2a5c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7791e791e71a4624abc0ee5f3b993837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70242058f5f445958cfc2f5cc97f9fc2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_539d613253f046d9ba3d5a6cca4e7336"}},"37e20b1658cf471eb5e9e3eb60d8f714":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78c4fcd456d043cabaf5cbbe2759162d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c250ff8c5f6741f7b8aeee35bb875ed0"}},"fe9857e31d144161ab3dfa0da694cfb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d6cff1d27b24792807bf5ddd1b2b98a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [00:00&lt;00:00, 19619169.62it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b5b1b3d8df54e93b536623d8ba108b2"}},"70242058f5f445958cfc2f5cc97f9fc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"539d613253f046d9ba3d5a6cca4e7336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78c4fcd456d043cabaf5cbbe2759162d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c250ff8c5f6741f7b8aeee35bb875ed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d6cff1d27b24792807bf5ddd1b2b98a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5b5b1b3d8df54e93b536623d8ba108b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5625556804e1402ea35bad12a50602a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b79f4a06afae43bfb8d52b8164550dcf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f693688ab84e4409864468718e1f65ea","IPY_MODEL_1fcad33212074d7190cee61b0acf06a1","IPY_MODEL_2932938c95c14112bac48bd31b2cb20a"]}},"b79f4a06afae43bfb8d52b8164550dcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f693688ab84e4409864468718e1f65ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_072664088ed34e049ccc45b1543235a3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46f5a980615c4cd388def319f7f3a721"}},"1fcad33212074d7190cee61b0acf06a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d2ccc5e585c42db99e35f967fb3ea10","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b107775747e4ebfb7b2e7f17817631e"}},"2932938c95c14112bac48bd31b2cb20a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b805a7f4aae64af4acea9567d2508e8a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:00&lt;00:00, 6894.20it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc81171d82814f8cb5447878eb0ff5e2"}},"072664088ed34e049ccc45b1543235a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46f5a980615c4cd388def319f7f3a721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d2ccc5e585c42db99e35f967fb3ea10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8b107775747e4ebfb7b2e7f17817631e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b805a7f4aae64af4acea9567d2508e8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc81171d82814f8cb5447878eb0ff5e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8883d141ffe74da8b8c13c1e58047513":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_355b3351b29d4961a4e5cdaacf262734","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1e483e2e124040fc8a035ea3179b189f","IPY_MODEL_a783b52295e2472e85da514318004f59","IPY_MODEL_8d71cb6a6c334edaaed30e4314db24f1"]}},"355b3351b29d4961a4e5cdaacf262734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e483e2e124040fc8a035ea3179b189f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a394c7b2e9d54998b47008230cca4e19","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_00721e39470c4c87843c62304fcf5eaa"}},"a783b52295e2472e85da514318004f59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fda2cb5f22654485ae6825284bb502da","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e4bb6fe52b94972a4e764cd3cba2861"}},"8d71cb6a6c334edaaed30e4314db24f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bb79ebc20ff3436ab81285dd53bf0f7d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:00&lt;00:00, 1109734.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2394553a493485198b4b25e4dbdaf41"}},"a394c7b2e9d54998b47008230cca4e19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"00721e39470c4c87843c62304fcf5eaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fda2cb5f22654485ae6825284bb502da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e4bb6fe52b94972a4e764cd3cba2861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb79ebc20ff3436ab81285dd53bf0f7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2394553a493485198b4b25e4dbdaf41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96e2e4cbff4f4b8ba62f8353f2a9c6f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b23c1c008bbf41f59e0e5605132fe900","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9a14590276dc4c5ca20dbceaacccbd72","IPY_MODEL_e00bb6d2dc014523a1df7681cd07dbc1","IPY_MODEL_a1918aae919e4493bf4880368a56e5ff"]}},"b23c1c008bbf41f59e0e5605132fe900":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a14590276dc4c5ca20dbceaacccbd72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_40b9c5938cf84c728b746e90602fd7e8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8671ca14c40e43fe85e76733243cf809"}},"e00bb6d2dc014523a1df7681cd07dbc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_79048debe5f040978bdd7d3a95a36478","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac3308818c5842d4887aa7e0db7cac7f"}},"a1918aae919e4493bf4880368a56e5ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f7be7a221d0a463abb1498227798797f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:00&lt;00:00, 7625.90it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33d595b780c34d358cf151b4c33a46f6"}},"40b9c5938cf84c728b746e90602fd7e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8671ca14c40e43fe85e76733243cf809":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"79048debe5f040978bdd7d3a95a36478":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac3308818c5842d4887aa7e0db7cac7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7be7a221d0a463abb1498227798797f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33d595b780c34d358cf151b4c33a46f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}